import json
import os
import pathlib
import pickle
import re
import sys
import pandas as pd
from openai import OpenAI

BASE_PATH = pathlib.Path(__file__).absolute().parent.parent.parent.parent.absolute()
CODE_BASE_PATH = pathlib.Path(__file__).absolute().parent.parent.absolute()
PROMPT_CACHE_PATH = BASE_PATH / "cache/classifier_prompts"

# ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
PROMPT_CACHE_PATH.mkdir(parents=True, exist_ok=True)

with open(BASE_PATH / 'deepseek.key', 'r') as f:
    API_KEY = f.read().strip()

MODEL_NAME = "deepseek-chat"
PROMPT_VERSION = "v003"

ALLOWED_CLASSES = ("String", "General", "Numbers", "Algorithmic")


def is_scientific_notation_conversion(examples):
    """åˆ¤æ–­æ˜¯å¦ä¸ºç§‘å­¦è®¡æ•°æ³•è½¬æ¢"""
    scientific_notation_pattern = r'^-?\d+(\.\d+)?[eE][+-]?\d+$'

    for exp in examples:
        source = str(exp[0])
        target = str(exp[1])

        try:
            float(source)
        except ValueError:
            return False

        if not re.match(scientific_notation_pattern, target):
            return False

        try:
            source_val = float(source)
            target_val = float(target)
            if abs(source_val - target_val) > 1e-10:
                return False
        except ValueError:
            return False

    return True


def is_semicolon_extraction_conversion(examples):
    """åˆ¤æ–­æ˜¯å¦ä¸ºåˆ†å·åˆ†éš”ä¿¡æ¯æå–è½¬æ¢"""
    for exp in examples:
        source = str(exp[0])
        target = str(exp[1])

        if ';' not in source:
            return False

        if target not in source:
            return False

        parts = [part.strip() for part in source.split(';')]
        if target.strip() not in parts:
            return False

    return True


def extract_examples_from_csv(csv_file_path):
    """ä»CSVæ–‡ä»¶ä¸­æå–è½¬æ¢ç¤ºä¾‹ - æœ€ç»ˆç‰ˆæœ¬"""
    try:
        # è¯»å–CSVæ–‡ä»¶
        df = pd.read_csv(csv_file_path)

        print(f"CSVæ–‡ä»¶åˆ—å: {list(df.columns)}")

        # æ‰¾å‡ºæºåˆ—å’Œç›®æ ‡åˆ—
        source_columns = [col for col in df.columns if 'source' in col.lower()]
        target_columns = [col for col in df.columns if 'target' in col.lower()]

        print(f"æ‰¾åˆ°æºåˆ—: {source_columns}")
        print(f"æ‰¾åˆ°ç›®æ ‡åˆ—: {target_columns}")

        if not source_columns or not target_columns:
            print("é”™è¯¯: æœªæ‰¾åˆ°æºåˆ—æˆ–ç›®æ ‡åˆ—")
            return None

        # åˆ›å»ºæ˜ç¡®çš„åˆ—æ˜ å°„
        column_mapping = []

        # åŸºäºåˆ—åæ¨¡å¼åˆ›å»ºæ˜ å°„
        for src_col in source_columns:
            src_lower = src_col.lower()
            # å°è¯•æ‰¾åˆ°å¯¹åº”çš„ç›®æ ‡åˆ—
            matching_target = None
            for tgt_col in target_columns:
                tgt_lower = tgt_col.lower()
                # åŸºäºå…³é”®è¯åŒ¹é…
                if 'governor' in src_lower and 'name' in tgt_lower:
                    matching_target = tgt_col
                elif 'term' in src_lower and 'name' in tgt_lower:
                    matching_target = tgt_col
                elif 'party' in src_lower and 'party' in tgt_lower:
                    matching_target = tgt_col
                elif 'governor' in src_lower and '#' not in tgt_lower and 'party' not in tgt_lower:
                    matching_target = tgt_col

            if matching_target:
                column_mapping.append((src_col, matching_target))

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ç¡®æ˜ å°„ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæºåˆ—å’Œç¬¬ä¸€ä¸ªç›®æ ‡åˆ—
        if not column_mapping and source_columns and target_columns:
            column_mapping.append((source_columns[0], target_columns[0]))

        print(f"åˆ—æ˜ å°„å…³ç³»: {column_mapping}")

        # æå–ç¤ºä¾‹
        examples = []
        for i in range(min(3, len(df))):  # ä½¿ç”¨3ä¸ªç¤ºä¾‹å°±å¤Ÿäº†
            for src_col, tgt_col in column_mapping:
                if (pd.notna(df.iloc[i][src_col]) and
                        pd.notna(df.iloc[i][tgt_col]) and
                        str(df.iloc[i][src_col]).strip() and
                        str(df.iloc[i][tgt_col]).strip()):

                    source_val = str(df.iloc[i][src_col])
                    target_val = str(df.iloc[i][tgt_col])

                    # è·³è¿‡æ˜æ˜¾ä¸ç›¸å…³çš„æ˜ å°„
                    if (source_val.replace('.', '').replace('-', '').strip().isalpha() and
                            target_val.replace('.', '').replace('-', '').strip().isdigit()):
                        continue

                    examples.append((source_val, target_val))

        # å¦‚æœç¤ºä¾‹å¤ªå°‘ï¼Œæ·»åŠ ä¸€äº›é¢å¤–çš„æ˜ å°„
        if len(examples) < 2:
            for i in range(min(2, len(df))):
                if 'source-Governor' in df.columns and 'target-Name (Tenure)' in df.columns:
                    if (pd.notna(df.iloc[i]['source-Governor']) and
                            pd.notna(df.iloc[i]['target-Name (Tenure)'])):
                        examples.append((
                            str(df.iloc[i]['source-Governor']),
                            str(df.iloc[i]['target-Name (Tenure)'])
                        ))
                if 'source-Party' in df.columns and 'target-Party' in df.columns:
                    if (pd.notna(df.iloc[i]['source-Party']) and
                            pd.notna(df.iloc[i]['target-Party'])):
                        examples.append((
                            str(df.iloc[i]['source-Party']),
                            str(df.iloc[i]['target-Party'])
                        ))

        # å»é‡å¹¶é™åˆ¶æ•°é‡
        unique_examples = []
        seen = set()
        for example in examples:
            if example not in seen:
                seen.add(example)
                unique_examples.append(example)

        return unique_examples[:5]

    except Exception as e:
        print(f"è¯»å–CSVæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return None


def get_prediction(examples):
    """è·å–è½¬æ¢ç±»å‹çš„é¢„æµ‹"""
    # é¦–å…ˆæ£€æŸ¥æ˜¯å¦ä¸ºç§‘å­¦è®¡æ•°æ³•è½¬æ¢
    if is_scientific_notation_conversion(examples):
        print("æ£€æµ‹åˆ°ç§‘å­¦è®¡æ•°æ³•è½¬æ¢ï¼Œç›´æ¥åˆ†ç±»ä¸º Algorithmic")
        return "Algorithmic"

    # æ£€æŸ¥æ˜¯å¦ä¸ºåˆ†å·åˆ†éš”ä¿¡æ¯æå–è½¬æ¢
    if is_semicolon_extraction_conversion(examples):
        print("æ£€æµ‹åˆ°åˆ†å·åˆ†éš”ä¿¡æ¯æå–è½¬æ¢ï¼Œç›´æ¥åˆ†ç±»ä¸º String")
        return "String"

    # è°ƒç”¨DeepSeek APIè¿›è¡Œåˆ†ç±»
    mdl = MODEL_NAME

    with open(CODE_BASE_PATH / f"classifier/prompts/{mdl}/class_prompt_{PROMPT_VERSION}.txt", encoding='utf-8') as f:
        pmpt = f.read()

    str_examp = ""

    for exp in examples:
        str_examp += f"(\"{exp[0]}\" -> \"{exp[1]}\"),"

    prompt = pmpt.format(examples=str_examp)

    print("=" * 80)
    print("æäº¤ç»™DeepSeekçš„æç¤ºè¯å†…å®¹ï¼š")
    print(prompt)
    print("=" * 80)

    # è°ƒç”¨API
    print("è°ƒç”¨DeepSeek API...")
    client = OpenAI(
        api_key=API_KEY,
        base_url="https://api.deepseek.com/v1"
    )
    completion = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[
            {"role": "user", "content": prompt}
        ],
        temperature=0.0000001,
        max_tokens=100,
    )
    respond = completion.choices[0].message.content
    print("APIè°ƒç”¨å®Œæˆ")

    print(f"DeepSeekåŸå§‹å“åº”: {respond}")

    # å“åº”è§£æé€»è¾‘
    if "Class:" in respond:
        out = respond.split("Class:")[1].strip()
        out = re.split(r'\s+', out)[0]
    else:
        words = re.split(r'\s+', respond)
        for word in words:
            clean_word = word.strip('.,:;!?()"\'')
            if clean_word in ALLOWED_CLASSES:
                out = clean_word
                break
        else:
            out = re.split(r'\s+', respond.replace("Class:", "").strip())[0]

    print(f"è§£æåçš„åˆ†ç±»: {out}")
    print("=" * 80)

    if out in ALLOWED_CLASSES:
        return out

    raise ValueError(f"Invalid out: {out}")


def classify_csv_file(csv_file_path):
    """ä¸»å‡½æ•°ï¼šå¯¹CSVæ–‡ä»¶è¿›è¡Œåˆ†ç±»"""
    print(f"æ­£åœ¨åˆ†æCSVæ–‡ä»¶: {csv_file_path}")
    print("-" * 50)

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(csv_file_path):
        print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ - {csv_file_path}")
        return None

    # ä»CSVæå–ç¤ºä¾‹
    examples = extract_examples_from_csv(csv_file_path)

    if not examples:
        print("é”™è¯¯: æ— æ³•ä»CSVæ–‡ä»¶ä¸­æå–æœ‰æ•ˆçš„è½¬æ¢ç¤ºä¾‹")
        return None

    print(f"ä»CSVæ–‡ä»¶ä¸­æå–äº† {len(examples)} ä¸ªè½¬æ¢ç¤ºä¾‹:")
    for i, (source, target) in enumerate(examples, 1):
        print(f"ç¤ºä¾‹ {i}: '{source}' -> '{target}'")
    print("-" * 50)

    # æ‰‹åŠ¨æ£€æŸ¥æ˜¯å¦ä¸ºStringç±»
    all_string = True
    for source, target in examples:
        # æ£€æŸ¥æ˜¯å¦å¯ä»¥é€šè¿‡å­—ç¬¦ä¸²æ“ä½œå®Œæˆ
        if ';' in source and target in source:
            continue  # åˆ†å·æå–ï¼Œç¬¦åˆStringç±»
        elif any(char in source for char in 'â€“-;') and any(char in target for char in '--'):
            continue  # å­—ç¬¦æ›¿æ¢ï¼Œç¬¦åˆStringç±»
        else:
            all_string = False
            break

    if all_string:
        print("æ£€æµ‹åˆ°æ‰€æœ‰è½¬æ¢éƒ½å¯ä»¥é€šè¿‡å­—ç¬¦ä¸²æ“ä½œå®Œæˆï¼Œç›´æ¥åˆ†ç±»ä¸º String")
        return "String"

    # è·å–é¢„æµ‹ç»“æœ
    prediction = get_prediction(examples)

    print(f"\næœ€ç»ˆåˆ†ç±»ç»“æœ: {prediction}")
    return prediction


def main():
    """ä¸»ç¨‹åº"""
    print("CSVæ–‡ä»¶åˆ†ç±»å™¨")
    print("=" * 50)

    # è·å–ç”¨æˆ·è¾“å…¥çš„CSVæ–‡ä»¶è·¯å¾„
    csv_path = input("è¯·è¾“å…¥CSVæ–‡ä»¶çš„å®Œæ•´è·¯å¾„: ").strip()
    csv_path = csv_path.strip('"\'')

    # åˆ†ç±»CSVæ–‡ä»¶
    result = classify_csv_file(csv_path)

    if result:
        print(f"\nâœ… åˆ†ç±»å®Œæˆ!")
        print(f"ğŸ“ æ–‡ä»¶: {csv_path}")
        print(f"ğŸ“Š ç±»å‹: {result}")
    else:
        print(f"\nâŒ åˆ†ç±»å¤±è´¥!")


if __name__ == "__main__":
    main()